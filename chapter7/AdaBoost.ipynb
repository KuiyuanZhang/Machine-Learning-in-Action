{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSimpData():\n",
    "    \"\"\" 测试数据\n",
    "    Returns:\n",
    "        dataArr   feature对应的数据集\n",
    "        labelArr  feature对应的分类标签\n",
    "    \"\"\"\n",
    "    dataArr = array([[1., 2.1], [2., 1.1], [1.3, 1.], [1., 1.], [2., 1.]])\n",
    "    labelArr = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return dataArr, labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataMat, classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stumpClassify(dataMat, dimen, threshVal, threshIneq):\n",
    "    \"\"\"stumpClassify(将数据集，按照feature列的value进行 二分法切分比较来赋值分类)\n",
    "\n",
    "    Args:\n",
    "        dataMat    Matrix数据集\n",
    "        dimen      特征列\n",
    "        threshVal  特征列要比较的值\n",
    "    Returns:\n",
    "        retArray 结果集\n",
    "    \"\"\"\n",
    "    # 默认都是1\n",
    "    retArray = ones((shape(dataMat)[0], 1))\n",
    "    # dataMat[:, dimen] 表示数据集中第dimen列的所有值\n",
    "    # threshIneq == 'lt'表示修改左边的值，gt表示修改右边的值\n",
    "    # print '-----', threshIneq, dataMat[:, dimen], threshVal\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMat[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMat[:, dimen] > threshVal] = -1.0\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStump(dataArr, labelArr, D):\n",
    "    \"\"\"buildStump(得到决策树的模型)\n",
    "\n",
    "    Args:\n",
    "        dataArr   特征标签集合\n",
    "        labelArr  分类标签集合\n",
    "        D         最初的特征权重值\n",
    "    Returns:\n",
    "        bestStump    最优的分类器模型\n",
    "        minError     错误率\n",
    "        bestClasEst  训练后的结果集\n",
    "    \"\"\"\n",
    "    # 转换数据\n",
    "    dataMat = mat(dataArr)\n",
    "    labelMat = mat(labelArr).T\n",
    "    # m行 n列\n",
    "    m, n = shape(dataMat)\n",
    "\n",
    "    # 初始化数据\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClasEst = mat(zeros((m, 1)))\n",
    "    # 初始化的最小误差为无穷大\n",
    "    minError = inf\n",
    "\n",
    "    # 循环所有的feature列，将列切分成 若干份，每一段以最左边的点作为分类节点\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMat[:, i].min()\n",
    "        rangeMax = dataMat[:, i].max()\n",
    "        # print 'rangeMin=%s, rangeMax=%s' % (rangeMin, rangeMax)\n",
    "        # 计算每一份的元素个数\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        # 例如： 4=(10-1)/2   那么  1-4(-1次)   1(0次)  1+1*4(1次)   1+2*4(2次)\n",
    "        # 所以： 循环 -1/0/1/2\n",
    "        for j in range(-1, int(numSteps)+1):\n",
    "            # go over less than and greater than\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                # 如果是-1，那么得到rangeMin-stepSize; 如果是numSteps，那么得到rangeMax\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                # 对单层决策树进行简单分类，得到预测的分类值\n",
    "                predictedVals = stumpClassify(dataMat, i, threshVal, inequal)\n",
    "                # print predictedVals\n",
    "                errArr = mat(ones((m, 1)))\n",
    "                # 正确为0，错误为1\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                # 计算 平均每个特征的概率0.2*错误概率的总和为多少，就知道错误率多高\n",
    "                # 例如： 一个都没错，那么错误率= 0.2*0=0 ， 5个都错，那么错误率= 0.2*5=1， 只错3个，那么错误率= 0.2*3=0.6\n",
    "                weightedError = D.T*errArr\n",
    "                '''\n",
    "                dim            表示 feature列\n",
    "                threshVal      表示树的分界值\n",
    "                inequal        表示计算树左右颠倒的错误率的情况\n",
    "                weightedError  表示整体结果的错误率\n",
    "                bestClasEst    预测的最优结果\n",
    "                '''\n",
    "                # print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "\n",
    "    # bestStump 表示分类器的结果，在第几个列上，用大于／小于比较，阈值是多少\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'ineq': 'lt', 'thresh': 1.3}, matrix([[ 0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D表示最初值，对1进行均分为5份，平均每一个初始的概率都为0.2\n",
    "# D的目的是为了计算错误概率： weightedError = D.T*errArr\n",
    "D = mat(ones((5, 1))/5)\n",
    "#print 'D=', D.T\n",
    "buildStump(dataMat, classLabels, D )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整AdaBoost算法的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr, labelArr, numIt=40):\n",
    "    \"\"\"adaBoostTrainDS(adaBoost训练过程放大)\n",
    "\n",
    "    Args:\n",
    "        dataArr   特征标签集合\n",
    "        labelArr  分类标签集合\n",
    "        numIt     实例数\n",
    "    Returns:\n",
    "        weakClassArr  弱分类器的集合\n",
    "        aggClassEst   预测的分类结果值\n",
    "    \"\"\"\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    # 初始化 D，设置每个特征的权重值，平均分为m份\n",
    "    D = mat(ones((m, 1))/m)\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        # 得到决策树的模型\n",
    "        bestStump, error, classEst = buildStump(dataArr, labelArr, D)\n",
    "\n",
    "        # alpha 目的主要是计算每一个分类器实例的权重(加和就是分类结果)\n",
    "        # 计算每个分类器的 alpha 权重值\n",
    "        alpha = float(0.5*log((1.0-error)/max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        # store Stump Params in Array\n",
    "        weakClassArr.append(bestStump)\n",
    "\n",
    "        # print \"alpha=%s, classEst=%s, bestStump=%s, error=%s \" % (alpha, classEst.T, bestStump, error)\n",
    "        # 分类正确：乘积为1，不会影响结果，-1主要是下面求e的-alpha次方\n",
    "        # 分类错误：乘积为 -1，结果会受影响，所以也乘以 -1\n",
    "        expon = multiply(-1*alpha*mat(labelArr).T, classEst)\n",
    "        # print '\\n'\n",
    "        # print 'labelArr=', labelArr\n",
    "        # print 'classEst=', classEst.T\n",
    "        # print '\\n'\n",
    "        # print '乘积: ', multiply(mat(labelArr).T, classEst).T\n",
    "        # 判断正确的，就乘以-1，否则就乘以1， 为什么？ 书上的公式。\n",
    "        # print '(-1取反)预测值expon=', expon.T\n",
    "        # 计算e的expon次方，然后计算得到一个综合的概率的值\n",
    "        # 结果发现： 判断错误的样本，D对于的样本权重值会变大。\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D/D.sum()\n",
    "        # print \"D: \", D.T\n",
    "        # print '\\n'\n",
    "\n",
    "        # 预测的分类结果值，在上一轮结果的基础上，进行加和操作\n",
    "        # print '当前的分类结果：', alpha*classEst.T\n",
    "        aggClassEst += alpha*classEst\n",
    "        # print \"叠加后的分类结果aggClassEst: \", aggClassEst.T\n",
    "        # sign 判断正为1， 0为0， 负为-1，通过最终加和的权重值，判断符号。\n",
    "        # 结果为：错误的样本标签集合，因为是 !=,那么结果就是0 正, 1 负\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(labelArr).T, ones((m, 1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        # print \"total error=%s \" % (errorRate)\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr, aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'alpha': 0.6931471805599453, 'dim': 0, 'ineq': 'lt', 'thresh': 1.3},\n",
       "  {'alpha': 0.9729550745276565, 'dim': 1, 'ineq': 'lt', 'thresh': 1.0},\n",
       "  {'alpha': 0.8958797346140273,\n",
       "   'dim': 0,\n",
       "   'ineq': 'lt',\n",
       "   'thresh': 0.90000000000000002}],\n",
       " matrix([[ 1.17568763],\n",
       "         [ 2.56198199],\n",
       "         [-0.77022252],\n",
       "         [-0.77022252],\n",
       "         [ 0.61607184]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray = adaBoostTrainDS(dataMat, classLabels, 9)\n",
    "classifierArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试算法：基于AdaBoost的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass, classifierArr):\n",
    "    # do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "    dataMat = mat(datToClass)\n",
    "    m = shape(dataMat)[0]\n",
    "    aggClassEst = mat(zeros((m, 1)))\n",
    "    # 循环 多个分类器\n",
    "    for i in range(len(classifierArr)):\n",
    "        # 前提： 我们已经知道了最佳的分类器的实例\n",
    "        # 通过分类器来核算每一次的分类结果，然后通过alpha*每一次的结果 得到最后的权重加和的值。\n",
    "        classEst = stumpClassify(dataMat, classifierArr[0][i]['dim'],classifierArr[0][i]['thresh'],classifierArr[0][i]['ineq']) \n",
    "        aggClassEst += classifierArr[0][i]['alpha']*classEst \n",
    "        print (aggClassEst)\n",
    "    return sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453}, {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565}, {'dim': 0, 'thresh': 0.90000000000000002, 'ineq': 'lt', 'alpha': 0.8958797346140273}], matrix([[ 1.17568763],\n",
      "        [ 2.56198199],\n",
      "        [-0.77022252],\n",
      "        [-0.77022252],\n",
      "        [ 0.61607184]]))\n"
     ]
    }
   ],
   "source": [
    "datArr, labelArr = loadSimpData()\n",
    "classifierArr = adaBoostTrainDS(datArr, labelArr, 30)\n",
    "print (classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0,0], classifierArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[5,5],[0,0]], classifierArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例 在一个难数据集上应用AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general function to parse tab -delimited floats\n",
    "def loadDataSet(fileName):\n",
    "    # get number of fields\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataArr = []\n",
    "    labelArr = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataArr.append(lineArr)\n",
    "        labelArr.append(float(curLine[-1]))\n",
    "    return dataArr, labelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dim': 9, 'thresh': 3.0, 'ineq': 'gt', 'alpha': 0.4616623792657674}, {'dim': 17, 'thresh': 52.5, 'ineq': 'gt', 'alpha': 0.31248245042467104}, {'dim': 3, 'thresh': 55.199999999999996, 'ineq': 'gt', 'alpha': 0.2868097320169577}, {'dim': 18, 'thresh': 62.300000000000004, 'ineq': 'lt', 'alpha': 0.23297004638939506}, {'dim': 10, 'thresh': 0.0, 'ineq': 'lt', 'alpha': 0.19803846151213741}, {'dim': 5, 'thresh': 2.0, 'ineq': 'gt', 'alpha': 0.18847887349020634}, {'dim': 12, 'thresh': 1.2, 'ineq': 'lt', 'alpha': 0.15227368997476778}, {'dim': 7, 'thresh': 1.2, 'ineq': 'gt', 'alpha': 0.15510870821690512}, {'dim': 5, 'thresh': 0.0, 'ineq': 'lt', 'alpha': 0.13536197353359405}, {'dim': 4, 'thresh': 28.799999999999997, 'ineq': 'lt', 'alpha': 0.12521587326132078}] \n",
      "-----\n",
      " [[-0.646419    0.53886223  0.91726555  0.21712009 -0.69768794  1.22181293\n",
      "   1.22748297  0.58145314 -0.40165729  0.03508613  0.27123572  0.59407783\n",
      "   1.53203035  0.64819347  1.04739323 -0.40165729 -1.02662219  0.5606821\n",
      "   0.34364609 -0.40784481 -0.02469954  1.53203035  1.1676973   1.0995114\n",
      "   0.73717581  0.23749438  0.52166747  0.85052522  0.5606821   1.69342306\n",
      "  -1.02662219 -0.03331166  0.95841088  0.6538635  -0.40165729 -1.58160132\n",
      "  -0.32315478 -0.69921001  1.22748297  0.23749438 -1.58160132  0.23749438\n",
      "  -0.03331166 -0.49069632 -0.81111385 -1.58160132 -1.27705394  1.22748297\n",
      "  -0.10329743 -1.33116957  0.91726555  0.59407783  0.91726555  0.5606821\n",
      "   0.20691998  0.27123572  0.5606821  -0.02469954 -0.70343447 -1.58160132\n",
      "   1.1676973   0.95841088 -0.37284836 -0.19233647  0.21712009  0.68306018\n",
      "   0.18462128  1.53203035  0.20077111  1.22748297  0.18537621  1.53203035\n",
      "  -0.01293737 -0.32647673  0.5606821  -0.03331166  1.31646531  1.69342306\n",
      "  -0.07846957  0.02322857 -0.70620467  1.2613064   0.21712009 -1.40405878\n",
      "   0.59407783  1.47224468 -0.40165729  0.5606821   0.89862521  1.22748297\n",
      "   0.40165729  0.20691998  1.1550726  -0.07279954  0.79073955  1.41702908\n",
      "   0.62790127 -0.40784481  1.1676973  -0.40784481  1.31646531 -0.95663642\n",
      "   0.4544483   0.90429525  0.29848817  0.89862521  0.50089643  1.1676973\n",
      "  -0.86522948  0.21712009 -0.35372918  0.85052522  1.22748297 -0.01293737\n",
      "   0.38747052  1.56689706  1.99797044  0.54030781  0.44691059  0.80958618\n",
      "   1.1676973  -1.22493577  1.22748297 -0.27513129  0.84485519  1.40550435\n",
      "  -0.38301695  0.48217959  0.07292214  0.86522948  0.5606821   0.5273375\n",
      "   1.22748297 -1.27705394 -0.40165729 -0.07846957  1.53203035  0.80958618\n",
      "   0.90429525  0.85052522 -0.12406847 -1.58160132  1.53203035  0.36264266\n",
      "   0.98760756  1.38320565  0.91726555 -0.24749538  1.42269911  1.31646531\n",
      "  -1.00798185  0.11221091  1.1550726   1.93818477  0.84485519  1.22748297\n",
      "   1.11413356  1.10095697  1.22181293 -0.36264266  0.5606821   0.58145314\n",
      "  -0.57967867  0.64819347  0.16432908  1.22748297  1.53203035  0.27366031\n",
      "  -0.63171474  0.91726555 -0.65827656  0.05809528 -0.65827656 -0.77909388\n",
      "   0.5606821   1.36456531 -1.24647954 -0.24026458 -0.65208904 -0.40165729\n",
      "   0.5606821  -1.40405878  1.11413356  1.36456531 -0.40784481  0.90429525\n",
      "   0.83188488  0.6538635   0.58145314  0.64654161 -0.01902951  1.69342306\n",
      "  -1.33116957  0.34364609  1.31646531  0.02322857 -0.0976274   1.1198036\n",
      "   0.21712009  1.22181293 -0.27513129  0.81111385  1.53203035 -0.07846957\n",
      "  -0.65208904  0.44124055  0.5606821   0.36264266  1.1550726   0.07292214\n",
      "  -0.03331166  0.89862521  0.84485519  1.20884263  1.53203035  0.5606821\n",
      "  -0.63790227  1.1676973   0.84485519 -0.39598725  0.9932776  -0.35372918\n",
      "   0.64819347  1.22748297  1.53203035 -0.65827656  0.5606821  -1.02662219\n",
      "   0.93811868 -0.39598725 -1.58160132  0.5606821   0.52166747  0.79073955\n",
      "  -0.32647673  1.22748297  1.1676973   0.27123572 -0.07424511 -1.33116957\n",
      "   0.91726555  0.54891992  0.6538635   0.59407783 -1.58160132 -0.40165729\n",
      "  -0.65208904 -0.02469954  1.53203035 -0.40784481  0.54030781  0.21712009\n",
      "  -0.95663642 -0.49069632 -0.01902951  1.1198036  -0.65827656  1.53203035\n",
      "   0.20691998  0.49937436  1.13595343 -0.01293737 -0.29542349  0.84485519\n",
      "   0.83188488  0.34364609  0.54030781  0.95675902  0.90429525  0.83188488\n",
      "  -0.65208904 -0.40165729 -1.58160132  0.38313956 -0.32924692  0.69768794\n",
      "   1.47224468  1.22748297  0.83188488  1.42269911 -0.65827656 -0.35372918\n",
      "  -0.01293737  1.53203035  0.95841088 -1.04249592  0.23749438  0.5606821\n",
      "   1.20719077  0.91726555 -0.10329743 -0.57967867  0.27123572  1.69342306\n",
      "   0.05809528 -0.65208904 -1.02662219  0.27123572  0.5606821 ]]\n"
     ]
    }
   ],
   "source": [
    "# 马疝病数据集\n",
    "# 训练集合\n",
    "datArr, labelArr = loadDataSet(\"horseColicTraining2.txt\")\n",
    "weakClassArr, aggClassEst = adaBoostTrainDS(datArr, labelArr, 10)\n",
    "print (weakClassArr, '\\n-----\\n', aggClassEst.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]\n",
      " [-0.69314718]\n",
      " [ 0.69314718]\n",
      " [ 0.69314718]]\n",
      "[[-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [ 1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [ 1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [ 0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [ 0.27980789]\n",
      " [-0.27980789]\n",
      " [-0.27980789]\n",
      " [-1.66610226]\n",
      " [-0.27980789]\n",
      " [-0.27980789]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集合\n",
    "testArr, testLabelArr = loadDataSet('horseColicTest2.txt')\n",
    "prediction10 = adaClassify(testArr, classifierArray)\n",
    "m = shape(dataArrTest)[0]\n",
    "errArr = mat(ones((m, 1)))\n",
    "errArr[prediction10 != mat(testLabelArr).T].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正确率，召回率，ROC曲线 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotROC(predStrengths, classLabels):\n",
    "    \"\"\"plotROC(打印ROC曲线，并计算AUC的面积大小)\n",
    "\n",
    "    Args:\n",
    "        predStrengths  最终预测结果的权重值\n",
    "        classLabels    原始数据的分类结果集\n",
    "    \"\"\"\n",
    "    # print 'predStrengths=', predStrengths\n",
    "    # print 'classLabels=', classLabels\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    # variable to calculate AUC\n",
    "    ySum = 0.0\n",
    "    # 对正样本的进行求和\n",
    "    numPosClas = sum(array(classLabels)==1.0)\n",
    "    # 正样本的概率\n",
    "    yStep = 1/float(numPosClas)\n",
    "    # 负样本的概率\n",
    "    xStep = 1/float(len(classLabels)-numPosClas)\n",
    "    # argsort函数返回的是数组值从小到大的索引值\n",
    "    # get sorted index, it's reverse\n",
    "    sortedIndicies = predStrengths.argsort()\n",
    "    # 测试结果是否是从小到大排列\n",
    "    # print 'sortedIndicies=', sortedIndicies, predStrengths[0, 176], predStrengths.min(), predStrengths[0, 293], predStrengths.max()\n",
    "\n",
    "    # 开始创建模版对象\n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(111)\n",
    "    # cursor光标值\n",
    "    cur = (1.0, 1.0)\n",
    "    # loop through all the values, drawing a line segment at each point\n",
    "    for index in sortedIndicies.tolist()[0]:\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0\n",
    "            delY = yStep\n",
    "        else:\n",
    "            delX = xStep\n",
    "            delY = 0\n",
    "            ySum += cur[1]\n",
    "        # draw line from cur to (cur[0]-delX, cur[1]-delY)\n",
    "        # 画点连线 (x1, x2, y1, y2)\n",
    "        # print cur[0], cur[0]-delX, cur[1], cur[1]-delY\n",
    "        ax.plot([cur[0], cur[0]-delX], [cur[1], cur[1]-delY], c='b')\n",
    "        cur = (cur[0]-delX, cur[1]-delY)\n",
    "    # 画对角的虚线线\n",
    "    ax.plot([0, 1], [0, 1], 'b--')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve for AdaBoost horse colic detection system')\n",
    "    # 设置画图的范围区间 (x1, x2, y1, y2)\n",
    "    ax.axis([0, 1, 0, 1])\n",
    "    plt.show()\n",
    "    '''\n",
    "    参考说明：http://blog.csdn.net/wenyusuran/article/details/39056013\n",
    "    为了计算 AUC ，我们需要对多个小矩形的面积进行累加。\n",
    "    这些小矩形的宽度是xStep，因此可以先对所有矩形的高度进行累加，最后再乘以xStep得到其总面积。\n",
    "    所有高度的和(ySum)随着x轴的每次移动而渐次增加。\n",
    "    '''\n",
    "    print (\"the Area Under the Curve is: \", ySum*xStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3vy9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114b4c7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Area Under the Curve is:  0.8582969635063604\n"
     ]
    }
   ],
   "source": [
    "plotROC(aggClassEst.T, labelArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
