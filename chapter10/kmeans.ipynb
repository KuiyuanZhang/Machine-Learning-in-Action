{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从文本中构建矩阵，加载文本文件，然后处理\n",
    "def loadDataSet(fileName):    # 通用函数，用来解析以 tab 键分隔的 floats（浮点数）\n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split('\\t')\n",
    "        fltLine = list(map(float,curLine))    # 映射所有的元素为 float（浮点数）类型\n",
    "        dataMat.append(fltLine)\n",
    "    return dataMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算两个向量的欧式距离（可根据场景选择）\n",
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2))) # la.norm(vecA-vecB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。\n",
    "def randCent(dataSet, k):\n",
    "    n = shape(dataSet)[1] # 列的数量\n",
    "    centroids = mat(zeros((k,n))) # 创建k个质心矩阵\n",
    "    for j in range(n): # 创建随机簇质心，并且在每一维的边界内\n",
    "        minJ = min(dataSet[:,j])    # 最小值\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)    # 范围 = 最大值 - 最小值\n",
    "        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,1))    # 随机生成\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat = mat(loadDataSet('testSet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min(datMat[:, 0])= [[-5.379713]]\n",
      "min(datMat[:, 1])= [[-4.232586]]\n",
      "max(datMat[:, 1])= [[ 5.1904]]\n",
      "max(datMat[:, 0])= [[ 4.838138]]\n"
     ]
    }
   ],
   "source": [
    "# 测试 randCent() 函数是否正常运行。\n",
    "# 首先，先看一下矩阵中的最大值与最小值\n",
    "print ('min(datMat[:, 0])=', min(datMat[:, 0]))\n",
    "print ('min(datMat[:, 1])=', min(datMat[:, 1]))\n",
    "print ('max(datMat[:, 1])=', max(datMat[:, 1]))\n",
    "print ('max(datMat[:, 0])=', max(datMat[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randCent(datMat, 2)= [[ 4.20873806 -0.79572311]\n",
      " [-3.03856257 -2.42663189]]\n"
     ]
    }
   ],
   "source": [
    "# 然后看看 randCent() 函数能否生成 min 到 max 之间的值\n",
    "print ('randCent(datMat, 2)=', randCent(datMat, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " distEclud(datMat[0], datMat[1])= 5.18463281668\n"
     ]
    }
   ],
   "source": [
    "# 最后测试一下距离计算方法\n",
    "print (' distEclud(datMat[0], datMat[1])=', distEclud(datMat[0], datMat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means 聚类算法\n",
    "# 该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。\n",
    "# 这个过程重复数次，知道数据点的簇分配结果不再改变位置。\n",
    "# 运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似，也可能会陷入局部最小值）\n",
    "def kMeans(dataSet, k, distMeas=distEclud, createCent=randCent):\n",
    "    m = shape(dataSet)[0]    # 行数\n",
    "    clusterAssment = mat(zeros((m, 2)))    # 创建一个与 dataSet 行数一样，但是有两列的矩阵，用来保存簇分配结果\n",
    "    centroids = createCent(dataSet, k)    # 创建质心，随机k个质心\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):    # 循环每一个数据点并分配到最近的质心中去\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])    # 计算数据点到质心的距离\n",
    "                if distJI < minDist:    # 如果距离比 minDist（最小距离）还小，更新 minDist（最小距离）和最小质心的 index（索引）\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i, 0] != minIndex:    # 簇分配结果改变\n",
    "                clusterChanged = True    # 簇改变\n",
    "                clusterAssment[i, :] = minIndex,minDist**2    # 更新簇分配结果为最小质心的 index（索引），minDist（最小距离）的平方\n",
    "        print (centroids)\n",
    "        for cent in range(k): # 更新质心\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:, 0].A==cent)[0]] # 获取该簇中的所有点\n",
    "            centroids[cent,:] = mean(ptsInClust, axis=0) # 将质心修改为簇中所有点的平均值，mean 就是求平均值的\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datMat = mat(loadDataSet('testSet.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.73037919  2.54220952]\n",
      " [ 1.74708628 -3.38448653]\n",
      " [-5.3291067   1.89562252]\n",
      " [-3.44054611 -3.24669643]]\n",
      "[[ 1.57139544  3.0829917 ]\n",
      " [ 2.65077367 -2.79019029]\n",
      " [-3.00984169  2.66771831]\n",
      " [-3.53973889 -2.89384326]]\n",
      "[[ 2.6265299   3.10868015]\n",
      " [ 2.65077367 -2.79019029]\n",
      " [-2.46154315  2.78737555]\n",
      " [-3.53973889 -2.89384326]]\n"
     ]
    }
   ],
   "source": [
    "# 该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。\n",
    "# 这个过程重复数次，知道数据点的簇分配结果不再改变位置。\n",
    "# 运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似）\n",
    "myCentroids, clustAssing = kMeans(datMat, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二分 KMeans 聚类算法, 基于 kMeans 基础之上的优化，以避免陷入局部最小值\n",
    "def biKMeans(dataSet, k, distMeas=distEclud):\n",
    "    m = shape(dataSet)[0]\n",
    "    clusterAssment = mat(zeros((m,2))) # 保存每个数据点的簇分配结果和平方误差\n",
    "    centroid0 = mean(dataSet, axis=0).tolist()[0] # 质心初始化为所有数据点的均值\n",
    "    centList =[centroid0] # 初始化只有 1 个质心的 list\n",
    "    for j in range(m): # 计算所有数据点到初始质心的距离平方误差\n",
    "        clusterAssment[j,1] = distMeas(mat(centroid0), dataSet[j,:])**2\n",
    "    while (len(centList) < k): # 当质心数量小于 k 时\n",
    "        lowestSSE = inf\n",
    "        for i in range(len(centList)): # 对每一个质心\n",
    "            ptsInCurrCluster = dataSet[nonzero(clusterAssment[:,0].A==i)[0],:] # 获取当前簇 i 下的所有数据点\n",
    "            centroidMat, splitClustAss = kMeans(ptsInCurrCluster, 2, distMeas) # 将当前簇 i 进行二分 kMeans 处理\n",
    "            sseSplit = sum(splitClustAss[:,1]) # 将二分 kMeans 结果中的平方和的距离进行求和\n",
    "            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:,0].A!=i)[0],1]) # 将未参与二分 kMeans 分配结果中的平方和的距离进行求和\n",
    "            print (\"sseSplit, and notSplit: \",sseSplit,sseNotSplit)\n",
    "            if (sseSplit + sseNotSplit) < lowestSSE:\n",
    "                bestCentToSplit = i\n",
    "                bestNewCents = centroidMat\n",
    "                bestClustAss = splitClustAss.copy()\n",
    "                lowestSSE = sseSplit + sseNotSplit\n",
    "        # 找出最好的簇分配结果    \n",
    "        bestClustAss[nonzero(bestClustAss[:,0].A == 1)[0],0] = len(centList) # 调用二分 kMeans 的结果，默认簇是 0,1. 当然也可以改成其它的数字\n",
    "        bestClustAss[nonzero(bestClustAss[:,0].A == 0)[0],0] = bestCentToSplit # 更新为最佳质心\n",
    "        print ('the bestCentToSplit is: ',bestCentToSplit)\n",
    "        print ('the len of bestClustAss is: ', len(bestClustAss))\n",
    "        # 更新质心列表\n",
    "        centList[bestCentToSplit] = bestNewCents[0,:].tolist()[0] # 更新原质心 list 中的第 i 个质心为使用二分 kMeans 后 bestNewCents 的第一个质心\n",
    "        centList.append(bestNewCents[1,:].tolist()[0]) # 添加 bestNewCents 的第二个质心\n",
    "        clusterAssment[nonzero(clusterAssment[:,0].A == bestCentToSplit)[0],:]= bestClustAss # 重新分配最好簇下的数据（质心）以及SSE\n",
    "    return mat(centList), clusterAssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datMat = mat(loadDataSet('testSet2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.30226645 -0.78422509]\n",
      " [-3.92909894  3.00174882]]\n",
      "[[ 1.96427811 -0.33909943]\n",
      " [-3.04879176  0.61459906]]\n",
      "[[ 2.63894744  0.08730749]\n",
      " [-2.986818    0.01960228]]\n",
      "[[ 2.71473038  0.18858278]\n",
      " [-2.9219568  -0.07998038]]\n",
      "sseSplit, and notSplit:  628.142598723 0.0\n",
      "the bestCentToSplit is:  0\n",
      "the len of bestClustAss is:  80\n",
      "[[ 3.97676971 -0.40412372]\n",
      " [ 3.85218934  3.12057917]]\n",
      "[[ 2.8692781  -2.54779119]\n",
      " [ 2.54391447  3.21299611]]\n",
      "[[ 2.80293085 -2.7315146 ]\n",
      " [ 2.6265299   3.10868015]]\n",
      "sseSplit, and notSplit:  69.3549846272 628.142598723\n",
      "[[-2.60167284  3.17186881]\n",
      " [-0.88112676  0.85536843]]\n",
      "[[-2.54183917  2.93204467]\n",
      " [-3.23296214 -2.5443645 ]]\n",
      "[[-2.46154315  2.78737555]\n",
      " [-3.38237045 -2.9473363 ]]\n",
      "sseSplit, and notSplit:  455.160581321 0.0\n",
      "the bestCentToSplit is:  1\n",
      "the len of bestClustAss is:  40\n"
     ]
    }
   ],
   "source": [
    "centList, myNewAssments = biKMeans(datMat, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centList= [[ 2.71473038  0.18858278]\n",
      " [-2.46154315  2.78737555]\n",
      " [-3.38237045 -2.9473363 ]]\n"
     ]
    }
   ],
   "source": [
    "print ('centList=', centList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
